{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-40254cd0dad7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler   \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(nn.Module):\n",
    "    def __init__(self, act_func):\n",
    "        super(Perceptron, self).__init__()\n",
    "        self.fc = nn.Linear(2, 1)\n",
    "        self.act_func = act_func\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if (self.act_func == 'sigmoid'):\n",
    "            return torch.sigmoid(self.fc(x))\n",
    "        elif (self.act_func == 'tanh'):\n",
    "            return (torch.tanh(self.fc(x)) + 1) / 2\n",
    "        elif (self.act_func == 'atan'):\n",
    "            return (torch.atan(self.fc(x)) + math.pi / 2) / math.pi\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, n_neurons, hidden_act_func, final_act_func):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, n_neurons)\n",
    "        self.fc2 = nn.Linear(n_neurons, 1)\n",
    "        self.haf = hidden_act_func\n",
    "        self.faf = final_act_func\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if (self.haf == 'sigmoid'):\n",
    "            x = torch.sigmoid(self.fc1(x))\n",
    "        elif (self.haf == 'tanh'):\n",
    "            x = torch.tanh(self.fc1(x))\n",
    "        elif (self.haf == 'atan'):\n",
    "            x = torch.atan(self.fc1(x))\n",
    "        elif (self.haf == 'relu'):\n",
    "            x = torch.relu(self.fc1(x))\n",
    "        else:\n",
    "            print('gg')\n",
    "            return 0\n",
    "        \n",
    "        if (self.faf == 'sigmoid'):\n",
    "            return torch.sigmoid(self.fc2(x))\n",
    "        elif (self.faf == 'tanh'):\n",
    "            return (torch.tanh(self.fc2(x)) + 1) / 2\n",
    "        elif (self.faf == 'atan'):\n",
    "            return (torch.atan(self.fc2(x)) + math.pi / 2) / math.pi\n",
    "        else:\n",
    "            print('gg')\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "class Data(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "class Data_without_targets(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    correct_results_sum = (torch.round(y_pred) == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, data_loader):\n",
    "    criterion = nn.BCELoss()\n",
    "    model.train()\n",
    "    for e in range(1, n_epochs + 1):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        for X_batch, y_batch in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred = model(X_batch)\n",
    "\n",
    "            loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "            acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    return [epoch_loss/len(data_loader), epoch_acc/len(data_loader)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_loader):\n",
    "    criterion = nn.BCELoss()\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in data_loader:\n",
    "            y_pred = model(X_batch)\n",
    "\n",
    "            loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "            acc = binary_acc(y_pred, y_batch.unsqueeze(1))        \n",
    "\n",
    "            test_loss += loss.item()\n",
    "            test_acc += acc.item()\n",
    "\n",
    "    return [test_loss/len(data_loader), test_acc/len(data_loader)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_meshgrid(x, y, h=.02, margin=1):\n",
    "    x_min, x_max = x.min() - margin, x.max() + margin\n",
    "    y_min, y_max = y.min() - margin, y.max() + margin\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "def plot_contours(ax, model, xx, yy, **params):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        y_pred = model(torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype=torch.float))\n",
    "        y_pred = y_pred.detach().numpy()\n",
    "        y_pred = y_pred.reshape(xx.shape)               \n",
    "        out = ax.contourf(xx, yy, y_pred, **params)\n",
    "    return out\n",
    "\n",
    "def plot_results(ax, model, X, y, title):\n",
    "    x1, x2 = (X.iloc[:, 0], X.iloc[:, 1])\n",
    "    xx, yy = make_meshgrid(x1, x2, margin=margin)\n",
    "    plot_contours(ax, model, xx, yy, cmap=plt.cm.RdYlGn, alpha=0.8)\n",
    "    ax.scatter(x1, x2, c=y, cmap=plt.cm.RdYlGn, s=50, edgecolors='k')\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xlabel('X 1')\n",
    "    ax.set_ylabel('X 2')\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 200\n",
    "batch_size_0 = 10\n",
    "batch_size_1 = 25\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0 = pd.read_csv('nn_0.csv').replace({'class' : {-1 : 0}})\n",
    "X_0 = data_0.iloc[:, 0:-1]\n",
    "y_0 = data_0.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = pd.read_csv('nn_1.csv').replace({'class' : {-1 : 0}})\n",
    "X_1 = data_1.iloc[:, 0:-1]\n",
    "y_1 = data_1.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.scatterplot(x='X1', y='X2', data=data_0, hue='class', ax=axes[0])\n",
    "sns.scatterplot(x='X1', y='X2', data=data_1, hue='class', ax=axes[1])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0_train, X_0_test, y_0_train, y_0_test = train_test_split(X_0, y_0, test_size=0.3, random_state=47)\n",
    "X_1_train, X_1_test, y_1_train, y_1_test = train_test_split(X_1, y_1, test_size=0.3, random_state=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_0 = Data(torch.FloatTensor(X_0_train.values), torch.FloatTensor(y_0_train.values))\n",
    "train_data_1 = Data(torch.FloatTensor(X_1_train.values), torch.FloatTensor(y_1_train.values))\n",
    "test_data_0 = Data(torch.FloatTensor(X_0_test.values), torch.FloatTensor(y_0_test.values))\n",
    "test_data_1 = Data(torch.FloatTensor(X_1_test.values), torch.FloatTensor(y_1_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_0 = DataLoader(dataset=train_data_0, batch_size=batch_size_0, shuffle=True)\n",
    "test_loader_0 = DataLoader(dataset=test_data_0, batch_size=batch_size_0)\n",
    "\n",
    "train_loader_1 = DataLoader(dataset=train_data_1, batch_size=batch_size_1, shuffle=True)\n",
    "test_loader_1 = DataLoader(dataset=test_data_1, batch_size=batch_size_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 0.2\n",
    "plt.figure(figsize=(12, 15))\n",
    "\n",
    "i = 1\n",
    "act_funcs = ['sigmoid', 'tanh', 'atan']\n",
    "optims = ['SGD', 'RMSProp', 'Adam']\n",
    "test_avg_loss_list = []\n",
    "\n",
    "for optim_element in optims:\n",
    "    for act_func in act_funcs:\n",
    "        perceptron = Perceptron(act_func)\n",
    "        if (optim_element == 'SGD'):\n",
    "            optimizer = optim.SGD(perceptron.parameters(), lr=learning_rate)\n",
    "        elif (optim_element == 'RMSProp'):\n",
    "            optimizer = optim.RMSprop(perceptron.parameters(), lr=learning_rate)\n",
    "        elif (optim_element == 'Adam'):\n",
    "            optimizer = optim.Adam(perceptron.parameters(), lr=learning_rate)\n",
    "            \n",
    "        [train_avg_loss, train_acc] = train(perceptron, optimizer, train_loader_0)\n",
    "        [test_avg_loss, test_acc] = test(perceptron, test_loader_0)\n",
    "        \n",
    "        test_avg_loss_list.append(test_avg_loss)\n",
    "        \n",
    "        print(act_func, optim_element)\n",
    "        print(f'Train: Avg.Loss: {train_avg_loss:.5f} | Acc: {train_acc:.3f}')\n",
    "        print(f'Test: Avg.Loss: {test_avg_loss:.5f} | Acc: {test_acc:.3f}')\n",
    "        print('____________________________________________________________')\n",
    "        \n",
    "        plot_results(plt.subplot(5, 3, i), perceptron, X_0, y_0, \n",
    "                     act_func + ' ' + optim_element + ', acc_score: ' + str(round(test_acc, 2)))\n",
    "        i = i + 1\n",
    "        \n",
    "plt.tight_layout()\n",
    "\n",
    "print('Test average loss = ' + str(round(np.average(np.array(test_avg_loss_list)), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 0.2\n",
    "plt.figure(figsize=(12, 15))\n",
    "\n",
    "i = 1\n",
    "act_funcs = ['sigmoid', 'tanh', 'atan']\n",
    "optims = ['SGD', 'RMSProp', 'Adam']\n",
    "test_avg_loss_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "for optim_element in optims:\n",
    "    for act_func in act_funcs:\n",
    "        perceptron = Perceptron(act_func)\n",
    "        if (optim_element == 'SGD'):\n",
    "            optimizer = optim.SGD(perceptron.parameters(), lr=learning_rate)\n",
    "        elif (optim_element == 'RMSProp'):\n",
    "            optimizer = optim.RMSprop(perceptron.parameters(), lr=learning_rate)\n",
    "        elif (optim_element == 'Adam'):\n",
    "            optimizer = optim.Adam(perceptron.parameters(), lr=learning_rate)\n",
    "            \n",
    "        [train_avg_loss, train_acc] = train(perceptron, optimizer, train_loader_1)\n",
    "        [test_avg_loss, test_acc] = test(perceptron, test_loader_1)\n",
    "        \n",
    "        test_avg_loss_list.append(test_avg_loss)\n",
    "        test_acc_list.append(test_acc)\n",
    "        \n",
    "        print(act_func, optim_element)\n",
    "        print(f'Train: Avg.Loss: {train_avg_loss:.5f} | Acc: {train_acc:.3f}')\n",
    "        print(f'Test: Avg.Loss: {test_avg_loss:.5f} | Acc: {test_acc:.3f}')\n",
    "        print('____________________________________________________________')\n",
    "        \n",
    "        plot_results(plt.subplot(5, 3, i), perceptron, X_1, y_1, \n",
    "                     act_func + ' ' + optim_element + ', acc_score: ' + str(round(test_acc, 2)))\n",
    "        i = i + 1\n",
    "        \n",
    "plt.tight_layout()\n",
    "print('Test average loss = ' + str(round(np.average(np.array(test_avg_loss_list)), 3)))\n",
    "print('Test average accuracy = ' + str(round(np.average(np.array(test_acc_list)), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "n_neurons = range(2, 11)\n",
    "hidden_act_funcs = ['sigmoid', 'tanh', 'atan', 'relu']\n",
    "final_act_funcs = ['sigmoid', 'tanh', 'atan']\n",
    "optims = ['SGD', 'RMSProp', 'Adam']\n",
    "results = pd.DataFrame(columns=['n_neurons', 'optimizer', 'hidden_act_func', 'final_act_func', 'Test avg. loss', 'Test acc.'])\n",
    "\n",
    "for n in n_neurons:\n",
    "    for optim_element in optims:\n",
    "        for hidden_act_func in hidden_act_funcs:\n",
    "            for final_act_func in act_funcs:\n",
    "                net = Net(n, hidden_act_func, final_act_func)\n",
    "                if (optim_element == 'SGD'):\n",
    "                    optimizer = optim.SGD(net.parameters(), lr=learning_rate)\n",
    "                elif (optim_element == 'RMSProp'):\n",
    "                    optimizer = optim.RMSprop(net.parameters(), lr=learning_rate)\n",
    "                elif (optim_element == 'Adam'):\n",
    "                    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "                [train_avg_loss, train_acc] = train(net, optimizer, train_loader_1)\n",
    "                [test_avg_loss, test_acc] = test(net, test_loader_1)\n",
    "\n",
    "                results =   results.append({'n_neurons': n, 'optimizer': optim_element, 'hidden_act_func': hidden_act_func, \n",
    "                                            'final_act_func': final_act_func, 'Test avg. loss' : test_avg_loss,\n",
    "                                            'Test acc.' : test_acc}, ignore_index=True)\n",
    "\n",
    "                print(n, optim_element, hidden_act_func, final_act_func)\n",
    "                print(f'Train: Avg.Loss: {train_avg_loss:.5f} | Acc: {train_acc:.3f}')\n",
    "                print(f'Test: Avg.Loss: {test_avg_loss:.5f} | Acc: {test_acc:.3f}')\n",
    "                print('____________________________________________________________')\n",
    "\n",
    "                i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(['Test acc.', 'Test avg. loss'], ascending=[0, 1]).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 0.2\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "n_neurons = [8, 7, 9]\n",
    "hidden_act_funcs = ['tanh', 'atan', 'tanh']\n",
    "final_act_funcs = ['tanh', 'tanh', 'sigmoid']\n",
    "optim_element = 'RMSProp'\n",
    "\n",
    "for i in range (0, 3):\n",
    "    net = Net(n_neurons[i], hidden_act_funcs[i], final_act_funcs[i])\n",
    "    optimizer = optim.RMSprop(net.parameters(), lr=learning_rate)\n",
    "    train(net, optimizer, train_loader_1)\n",
    "    plot_results(plt.subplot(1, 3, i + 1), net, X_1_test, y_1_test, \n",
    "                 'n_neurons = ' + str(n_neurons[i]) + '\\n ' + optim_element \n",
    "                 + '\\nhidden act. func = ' + hidden_act_funcs[i] + '\\n final act. func = ' + final_act_funcs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
